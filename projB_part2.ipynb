{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_set_df = pd.read_csv(\"./data_movie_lens_100k/ratings_all_development_set.csv\")\n",
    "users_df = pd.read_csv(\"./data_movie_lens_100k/user_info.csv\")\n",
    "movies_df = pd.read_csv(\"./data_movie_lens_100k/movie_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id  item_id  rating\n",
      "0          772       36       3\n",
      "1          471      228       5\n",
      "2          641      401       4\n",
      "3          312       98       4\n",
      "4           58      504       5\n",
      "...        ...      ...     ...\n",
      "89987      415      813       4\n",
      "89988      842      120       3\n",
      "89989      574      505       2\n",
      "89990      757      472       5\n",
      "89991      503      204       3\n",
      "\n",
      "[89992 rows x 3 columns]\n",
      "     user_id  age  is_male  orig_user_id\n",
      "0          0   24        1             1\n",
      "1          1   53        0             2\n",
      "2          2   23        1             3\n",
      "3          3   24        1             4\n",
      "4          4   33        0             5\n",
      "..       ...  ...      ...           ...\n",
      "938      938   26        0           939\n",
      "939      939   32        1           940\n",
      "940      940   20        1           941\n",
      "941      941   48        0           942\n",
      "942      942   22        1           943\n",
      "\n",
      "[943 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(ratings_set_df)\n",
    "print(users_df)\n",
    "#print(movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ratings_features = ratings_set_df[[\"user_id\", \"item_id\"]]\n",
    "ratings = ratings_set_df[\"rating\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(ratings_features, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SVD' object has no attribute 'pu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 32\u001b[0m\n\u001b[1;32m     13\u001b[0m trainset \u001b[38;5;241m=\u001b[39m ratings_df\u001b[38;5;241m.\u001b[39mbuild_full_trainset()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# for n_factors in [3]:\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#     ## Fit model like our M3\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#     model = SVD(n_factors=n_factors)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#     print(\"pu:\", model.pu)\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m user_vectors \u001b[38;5;241m=\u001b[39m \u001b[43msvd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpu\u001b[49m\n\u001b[1;32m     33\u001b[0m item_vectors \u001b[38;5;241m=\u001b[39m svd\u001b[38;5;241m.\u001b[39mqi\n\u001b[1;32m     35\u001b[0m user_features \u001b[38;5;241m=\u001b[39m users_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_male\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SVD' object has no attribute 'pu'"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, NormalPredictor, Reader, SVD, accuracy\n",
    "\n",
    "svd = SVD(\n",
    "    n_factors = 10,\n",
    "    n_epochs=50\n",
    ")\n",
    "\n",
    "reader = Reader(\n",
    "    line_format='user item rating', sep=',',\n",
    "    rating_scale=(1, 5), skip_lines=1)\n",
    "ratings_df = Dataset.load_from_df(ratings_set_df[['user_id', 'item_id','rating']], reader=reader)\n",
    "\n",
    "trainset = ratings_df.build_full_trainset()\n",
    "\n",
    "# for n_factors in [3]:\n",
    "#     ## Fit model like our M3\n",
    "#     model = SVD(n_factors=n_factors)\n",
    "#     model.fit(trainset)\n",
    "\n",
    "#     print(\"global mean:\")\n",
    "#     print(model.trainset.global_mean)\n",
    "#     print(\"shape of bias_per_item: \")\n",
    "#     print(model.bi.shape)\n",
    "#     print(\"shape of bias_per_user: \")\n",
    "#     print(model.bu.shape)\n",
    "#     print(\"shape of U (per user vectors): \")\n",
    "#     print(model.pu.shape)\n",
    "#     print(\"shape of V (per item vectors): \")\n",
    "#     print(model.qi.shape)\n",
    "\n",
    "#     print(\"pu:\", model.pu)\n",
    "user_vectors = svd.pu\n",
    "item_vectors = svd.qi\n",
    "\n",
    "user_features = users_df[['user_id', 'age', 'is_male']].values\n",
    "item_features = movies_df[['release_year']].values\n",
    "\n",
    "user_ids = user_features[:,0]\n",
    "# print(\"user_ids:\", user_ids)\n",
    "inner_uids = [trainset.to_inner_uid(uid) for uid in user_ids]\n",
    "# print(\"inner_uids:\", inner_uids)\n",
    "\n",
    "concat_users = np.concatenate((user_features, user_vectors[inner_uids]))\n",
    "item_ids = item_features[:,0]\n",
    "# print(\"user_ids:\", user_ids)\n",
    "inner_iids = [trainset.to_inner_iid(iid) for iid in item_ids]\n",
    "# print(\"inner_uids:\", inner_uids)\n",
    "\n",
    "'''\n",
    "features = []\n",
    "for pair in test_pairs:\n",
    "    i, j = pair\n",
    "    if i in svd.users:\n",
    "        u_i = svd.U[SVD.to_internal_uid(i)]\n",
    "    else:\n",
    "        u_i = 0 vector\n",
    "    #(same for item)\n",
    "    feature = [u_i, v_j, user_info[i], item_info[j]]\n",
    "    features.append(feature)\n",
    "'''\n",
    "\n",
    "def get_features_for_user(user_id):\n",
    "    return []\n",
    "\n",
    "def get_features_for_item(item_id):\n",
    "    return []\n",
    "\n",
    "features = []\n",
    "for i, j in X_train:\n",
    "    u_i = np.zeros((svd.pu.shape[0]))\n",
    "    if trainset.knows_user(i):\n",
    "        u_i = user_vectors[trainset.to_inner_uid(i)]\n",
    "    m_j = np.zeros((user_vectors.shape[0]))\n",
    "    if trainset.knows_item(j):\n",
    "        m_j = item_vectors[trainset.to_inner_iid(j)]\n",
    "    features.append(np.concatenate((u_i, m_j, get_features_for_user(i), get_features_for_item(j))))\n",
    "        \n",
    "user_vectors = np.resize(user_vectors, (item_features.shape[0], user_vectors.shape[1]))\n",
    "item_vectors = np.resize(item_vectors, (item_features.shape[0], item_vectors.shape[1]))\n",
    "\n",
    "user_features = np.resize(user_features, (item_features.shape[0], user_features.shape[1]))\n",
    "\n",
    "print(\"user vectors shape:\", user_vectors.shape)\n",
    "print(\"item vectors shape:\", item_vectors.shape)\n",
    "print(\"user features:\", user_features)\n",
    "\n",
    "print(item_features.shape)\n",
    "\n",
    "feature_vectors = np.concatenate((user_vectors, item_vectors, user_features, item_features), axis=1)\n",
    "print(\"feature vectors shape:\", feature_vectors.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1681, 89992]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m labels \u001b[38;5;241m=\u001b[39m (ratings \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m      7\u001b[0m SEED \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12345\u001b[39m\n\u001b[0;32m----> 9\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_vectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSEED\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cs135_env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/cs135_env/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2614\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2612\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2614\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2616\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   2617\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2618\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[1;32m   2619\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/cs135_env/lib/python3.10/site-packages/sklearn/utils/validation.py:455\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \n\u001b[1;32m    438\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    454\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[0;32m--> 455\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/cs135_env/lib/python3.10/site-packages/sklearn/utils/validation.py:409\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    407\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    412\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1681, 89992]"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ratings = ratings_set_df['rating'].values\n",
    "\n",
    "labels = (ratings >= 4.5).astype(int)\n",
    "\n",
    "SEED = 12345\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_vectors, labels, test_size=0.25, random_state=SEED)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs135_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
