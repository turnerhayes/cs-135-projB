{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import Dataset, NormalPredictor, Reader, SVD, accuracy\n",
    "from train_valid_test_loader import load_train_valid_test_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_set_df = pd.read_csv(\"./data_movie_lens_100k/ratings_all_development_set.csv\")\n",
    "users_df = pd.read_csv(\"./data_movie_lens_100k/user_info.csv\")\n",
    "movies_df = pd.read_csv(\"./data_movie_lens_100k/movie_info.csv\")\n",
    "train_tuple, valid_tuple, test_tuple, n_users, n_items = \\\n",
    "        load_train_valid_test_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id  item_id  rating\n",
      "0          772       36       3\n",
      "1          471      228       5\n",
      "2          641      401       4\n",
      "3          312       98       4\n",
      "4           58      504       5\n",
      "...        ...      ...     ...\n",
      "89987      415      813       4\n",
      "89988      842      120       3\n",
      "89989      574      505       2\n",
      "89990      757      472       5\n",
      "89991      503      204       3\n",
      "\n",
      "[89992 rows x 3 columns]\n",
      "     user_id  age  is_male  orig_user_id\n",
      "0          0   24        1             1\n",
      "1          1   53        0             2\n",
      "2          2   23        1             3\n",
      "3          3   24        1             4\n",
      "4          4   33        0             5\n",
      "..       ...  ...      ...           ...\n",
      "938      938   26        0           939\n",
      "939      939   32        1           940\n",
      "940      940   20        1           941\n",
      "941      941   48        0           942\n",
      "942      942   22        1           943\n",
      "\n",
      "[943 rows x 4 columns]\n",
      "      item_id                                      title  release_year  \\\n",
      "0           0                           Toy Story (1995)          1995   \n",
      "1           1                           GoldenEye (1995)          1995   \n",
      "2           2                          Four Rooms (1995)          1995   \n",
      "3           3                          Get Shorty (1995)          1995   \n",
      "4           4                             Copycat (1995)          1995   \n",
      "...       ...                                        ...           ...   \n",
      "1676     1676                          Mat' i syn (1997)          1998   \n",
      "1677     1677                           B. Monkey (1998)          1998   \n",
      "1678     1678                       Sliding Doors (1998)          1998   \n",
      "1679     1679                        You So Crazy (1994)          1994   \n",
      "1680     1680  Scream of Stone (Schrei aus Stein) (1991)          1996   \n",
      "\n",
      "      orig_item_id  \n",
      "0                1  \n",
      "1                2  \n",
      "2                3  \n",
      "3                4  \n",
      "4                5  \n",
      "...            ...  \n",
      "1676          1678  \n",
      "1677          1679  \n",
      "1678          1680  \n",
      "1679          1681  \n",
      "1680          1682  \n",
      "\n",
      "[1681 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(ratings_set_df)\n",
    "print(users_df)\n",
    "print(movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tuple_to_surprise_dataset(tupl):\n",
    "    \"\"\"\n",
    "    This function convert a subset in the tuple form to a `surprise` dataset. \n",
    "    \"\"\"\n",
    "    ratings_dict = {\n",
    "        \"userID\": tupl[0],\n",
    "        \"itemID\": tupl[1],\n",
    "        \"rating\": tupl[2],\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(ratings_dict)\n",
    "\n",
    "    # A reader is still needed but only the rating_scale param is requiered.\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "    # The columns must correspond to user id, item id and ratings (in that order).\n",
    "    dataset = Dataset.load_from_df(df[[\"userID\", \"itemID\", \"rating\"]], reader)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprise_train = tuple_to_surprise_dataset(train_tuple).build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = SVD(\n",
    "    n_factors = 10,\n",
    "    n_epochs = 50,\n",
    ")\n",
    "\n",
    "svd.fit(surprise_train)\n",
    "user_ids = [surprise_train.to_inner_uid(uid) for uid in train_tuple[0]]\n",
    "user_factors = svd.pu[user_ids]\n",
    "item_ids = [surprise_train.to_inner_iid(iid) for iid in train_tuple[1]]\n",
    "item_factors = svd.qi[item_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users_df shape: (943, 4)\n",
      "movies_df shape: (1681, 4)\n",
      "item_factors shape: (70000, 10)\n",
      "user_factors shape: (70000, 10)\n",
      "item id train tuple length: 70000\n",
      "unique items in train tuple: 1626\n"
     ]
    }
   ],
   "source": [
    "print(\"users_df shape:\", users_df.shape)\n",
    "print(\"movies_df shape:\", movies_df.shape)\n",
    "print(\"item_factors shape:\", item_factors.shape)\n",
    "print(\"user_factors shape:\", user_factors.shape)\n",
    "print(\"item id train tuple length:\", len(train_tuple[1]))\n",
    "print(\"unique items in train tuple:\", len(set(train_tuple[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 70000 and the array at index 1 has size 1681",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m user_vectors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack((svd\u001b[38;5;241m.\u001b[39mpu, users_df))\n\u001b[0;32m----> 2\u001b[0m movies_vectors \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovies_df\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/shape_base.py:359\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _nx\u001b[38;5;241m.\u001b[39mconcatenate(arrs, \u001b[38;5;241m0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype, casting\u001b[38;5;241m=\u001b[39mcasting)\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 70000 and the array at index 1 has size 1681"
     ]
    }
   ],
   "source": [
    "user_vectors = np.hstack((svd.pu, users_df))\n",
    "movies_vectors = np.hstack((item_factors, movies_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 943 and the array at index 1 has size 1681",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m combined_vectors \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43musers_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovies_df\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/shape_base.py:359\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _nx\u001b[38;5;241m.\u001b[39mconcatenate(arrs, \u001b[38;5;241m0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype, casting\u001b[38;5;241m=\u001b[39mcasting)\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 943 and the array at index 1 has size 1681"
     ]
    }
   ],
   "source": [
    "combined_vectors = np.hstack([users_df, movies_df])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs135_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
