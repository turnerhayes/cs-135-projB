{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from surprise import Dataset, NormalPredictor, Reader, SVD, accuracy, Trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_set_df = pd.read_csv(\"./data_movie_lens_100k/ratings_all_development_set.csv\")\n",
    "users_df = pd.read_csv(\"./data_movie_lens_100k/user_info.csv\")\n",
    "movies_df = pd.read_csv(\"./data_movie_lens_100k/movie_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id  item_id  rating\n",
      "0          772       36       3\n",
      "1          471      228       5\n",
      "2          641      401       4\n",
      "3          312       98       4\n",
      "4           58      504       5\n",
      "...        ...      ...     ...\n",
      "89987      415      813       4\n",
      "89988      842      120       3\n",
      "89989      574      505       2\n",
      "89990      757      472       5\n",
      "89991      503      204       3\n",
      "\n",
      "[89992 rows x 3 columns]\n",
      "     user_id  age  is_male  orig_user_id\n",
      "0          0   24        1             1\n",
      "1          1   53        0             2\n",
      "2          2   23        1             3\n",
      "3          3   24        1             4\n",
      "4          4   33        0             5\n",
      "..       ...  ...      ...           ...\n",
      "938      938   26        0           939\n",
      "939      939   32        1           940\n",
      "940      940   20        1           941\n",
      "941      941   48        0           942\n",
      "942      942   22        1           943\n",
      "\n",
      "[943 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(ratings_set_df)\n",
    "print(users_df)\n",
    "#print(movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ratings_features = ratings_set_df[[\"user_id\", \"item_id\"]]\n",
    "ratings = ratings_set_df[\"rating\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(ratings_features, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_valid_test_loader import load_train_valid_test_datasets\n",
    "\n",
    "# Load the dataset in the same way as the main problem \n",
    "train_tuple, valid_tuple, test_tuple, n_users, n_items = \\\n",
    "        load_train_valid_test_datasets()\n",
    "\n",
    "\n",
    "def tuple_to_surprise_dataset(tupl):\n",
    "    \"\"\"\n",
    "    This function convert a subset in the tuple form to a `surprise` dataset. \n",
    "    \"\"\"\n",
    "    ratings_dict = {\n",
    "        \"userID\": tupl[0],\n",
    "        \"itemID\": tupl[1],\n",
    "        \"rating\": tupl[2],\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(ratings_dict)\n",
    "\n",
    "    # A reader is still needed but only the rating_scale param is requiered.\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "    # The columns must correspond to user id, item id and ratings (in that order).\n",
    "    dataset = Dataset.load_from_df(df[[\"userID\", \"itemID\", \"rating\"]], reader)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "## Below we train an SVD model and get its vectors \n",
    "\n",
    "# train an SVD model using the training set\n",
    "trainset = tuple_to_surprise_dataset(train_tuple).build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_features_for_user(user_id):\n",
    "    return np.array(users_df[users_df[\"user_id\"] == user_id].iloc[0][[\"age\", \"is_male\"]])\n",
    "\n",
    "def get_features_for_item(item_id):\n",
    "    return np.array(movies_df[movies_df[\"item_id\"] == item_id].iloc[0][[\"release_year\"]])\n",
    "\n",
    "def get_rating(user_id, item_id, features_df: pd.DataFrame):\n",
    "    return features_df[\n",
    "        (features_df[\"user_id\"] == user_id) &\n",
    "            (features_df[\"item_id\"] == item_id)\n",
    "    ].iloc[0][\"rating\"]\n",
    "\n",
    "def get_feature_vectors(data_tuple, svd: SVD, trainset: Trainset):\n",
    "    user_vectors = svd.pu\n",
    "    item_vectors = svd.qi\n",
    "    \n",
    "    features = np.zeros(\n",
    "        (\n",
    "            len(data_tuple[0]),\n",
    "            user_vectors.shape[1] + item_vectors.shape[1] + len([\"age\", \"is_male\"]) + len([\"release_year\"])\n",
    "        )\n",
    "    )\n",
    "    ratings = []\n",
    "    for index in range(0, len(data_tuple[0])):\n",
    "        user_id = data_tuple[0][index]\n",
    "        item_id = data_tuple[1][index]\n",
    "        u_i = np.zeros((user_vectors.shape[1]))\n",
    "        if trainset.knows_user(user_id):\n",
    "            u_i = user_vectors[trainset.to_inner_uid(user_id)]\n",
    "        m_j = np.zeros((item_vectors.shape[1]))\n",
    "        if trainset.knows_item(item_id):\n",
    "            m_j = item_vectors[trainset.to_inner_iid(item_id)]\n",
    "        user_features = get_features_for_user(user_id)\n",
    "        item_features = get_features_for_item(item_id)\n",
    "        feature_vector = np.concatenate(\n",
    "            (\n",
    "                u_i,\n",
    "                m_j,\n",
    "                user_features,\n",
    "                item_features,\n",
    "            ),\n",
    "            axis=0\n",
    "        )\n",
    "        features[index] = feature_vector\n",
    "        \n",
    "        ratings.append(1 if data_tuple[2][index] > 4.5 else 0)\n",
    "    \n",
    "    return features, ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = SVD(\n",
    "    n_factors = 10,\n",
    "    n_epochs=50\n",
    ")\n",
    "\n",
    "svd.fit(trainset)\n",
    "\n",
    "features_train, ratings_train = get_feature_vectors(train_tuple, svd, trainset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thayes/miniconda3/envs/cs135_env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/thayes/miniconda3/envs/cs135_env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "mlp = MLPClassifier(\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"solver\": [\"lbfgs\", \"adam\"],\n",
    "    \"activation\": [\"relu\", \"tanh\"],\n",
    "    \"hidden_layer_sizes\": [(100,), (50,)],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    estimator=mlp,\n",
    "    param_grid=param_grid,\n",
    "    refit=True,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "gs.fit(features_train, ratings_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    " \n",
    "roc_disp = RocCurveDisplay.from_estimator(gs.best_estimator_, features_train, ratings_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs135_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
