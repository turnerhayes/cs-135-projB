{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_set_df = pd.read_csv(\"./data_movie_lens_100k/ratings_all_development_set.csv\")\n",
    "users_df = pd.read_csv(\"./data_movie_lens_100k/user_info.csv\")\n",
    "movies_df = pd.read_csv(\"./data_movie_lens_100k/movie_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       user_id  item_id  rating\n",
      "0          772       36       3\n",
      "1          471      228       5\n",
      "2          641      401       4\n",
      "3          312       98       4\n",
      "4           58      504       5\n",
      "...        ...      ...     ...\n",
      "89987      415      813       4\n",
      "89988      842      120       3\n",
      "89989      574      505       2\n",
      "89990      757      472       5\n",
      "89991      503      204       3\n",
      "\n",
      "[89992 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(ratings_set_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     user_id  age  is_male  orig_user_id\n",
      "0          0   24        1             1\n",
      "1          1   53        0             2\n",
      "2          2   23        1             3\n",
      "3          3   24        1             4\n",
      "4          4   33        0             5\n",
      "..       ...  ...      ...           ...\n",
      "938      938   26        0           939\n",
      "939      939   32        1           940\n",
      "940      940   20        1           941\n",
      "941      941   48        0           942\n",
      "942      942   22        1           943\n",
      "\n",
      "[943 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(users_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      item_id                                      title  release_year  \\\n",
      "0           0                           Toy Story (1995)          1995   \n",
      "1           1                           GoldenEye (1995)          1995   \n",
      "2           2                          Four Rooms (1995)          1995   \n",
      "3           3                          Get Shorty (1995)          1995   \n",
      "4           4                             Copycat (1995)          1995   \n",
      "...       ...                                        ...           ...   \n",
      "1676     1676                          Mat' i syn (1997)          1998   \n",
      "1677     1677                           B. Monkey (1998)          1998   \n",
      "1678     1678                       Sliding Doors (1998)          1998   \n",
      "1679     1679                        You So Crazy (1994)          1994   \n",
      "1680     1680  Scream of Stone (Schrei aus Stein) (1991)          1996   \n",
      "\n",
      "      orig_item_id  \n",
      "0                1  \n",
      "1                2  \n",
      "2                3  \n",
      "3                4  \n",
      "4                5  \n",
      "...            ...  \n",
      "1676          1678  \n",
      "1677          1679  \n",
      "1678          1680  \n",
      "1679          1681  \n",
      "1680          1682  \n",
      "\n",
      "[1681 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 10)\n",
      "(1626, 10)\n",
      "(943, 2)\n",
      "(1681, 1)\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, NormalPredictor, Reader, SVD, accuracy\n",
    "\n",
    "\n",
    "from train_valid_test_loader import load_train_valid_test_datasets\n",
    "\n",
    "# Load the dataset in the same way as the main problem \n",
    "train_tuple, valid_tuple, test_tuple, n_users, n_items = \\\n",
    "        load_train_valid_test_datasets()\n",
    "\n",
    "\n",
    "def tuple_to_surprise_dataset(tupl):\n",
    "    \"\"\"\n",
    "    This function convert a subset in the tuple form to a `surprise` dataset. \n",
    "    \"\"\"\n",
    "    ratings_dict = {\n",
    "        \"userID\": tupl[0],\n",
    "        \"itemID\": tupl[1],\n",
    "        \"rating\": tupl[2],\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(ratings_dict)\n",
    "\n",
    "    # A reader is still needed but only the rating_scale param is requiered.\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "    # The columns must correspond to user id, item id and ratings (in that order).\n",
    "    dataset = Dataset.load_from_df(df[[\"userID\", \"itemID\", \"rating\"]], reader)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "trainset = tuple_to_surprise_dataset(train_tuple).build_full_trainset()\n",
    "\n",
    "algo = SVD(n_factors=10)\n",
    "\n",
    "algo.fit(trainset)\n",
    "\n",
    "# uid = valid_tuple[0][0]\n",
    "# iid = valid_tuple[1][0]\n",
    "# rui = valid_tuple[2][0]\n",
    "\n",
    "# mu = algo.trainset.global_mean # SVD does not even fit mu -- it directly use the rating mean \n",
    "# bu = algo.bu[trainset.to_inner_uid(uid)]\n",
    "# bi = algo.bi[trainset.to_inner_iid(iid)] \n",
    "# pu = algo.pu[trainset.to_inner_uid(uid)] \n",
    "# qi = algo.qi[trainset.to_inner_iid(iid)]\n",
    "\n",
    "user_vectors = algo.pu\n",
    "item_vectors = algo.qi\n",
    "\n",
    "print(user_vectors.shape)\n",
    "print(item_vectors.shape)\n",
    "\n",
    "user_features = users_df[['age', 'is_male']].values\n",
    "item_features = movies_df[['release_year']].values\n",
    "\n",
    "print(user_features.shape)\n",
    "print(item_features.shape)\n",
    "\n",
    "\n",
    "# user_vectors = np.resize(user_vectors, (item_features.shape[0], user_vectors.shape[1]))\n",
    "# item_vectors = np.resize(item_vectors, (item_features.shape[0], item_vectors.shape[1]))\n",
    "\n",
    "# user_features = np.resize(user_features, (item_features.shape[0], user_features.shape[1]))\n",
    "\n",
    "\n",
    "# print(user_features)\n",
    "\n",
    "# print(item_features.shape)\n",
    "\n",
    "# feature_vectors = np.concatenate((user_vectors, item_vectors, user_features, item_features), axis=1)\n",
    "#print(feature_vectors)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89992,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1681, 89992]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[127], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(labels\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      7\u001b[0m SEED \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12345\u001b[39m\n\u001b[0;32m----> 9\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_vectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSEED\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/cs135_env/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2559\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_arrays \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2557\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt least one array required as input\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2559\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2561\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   2562\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2563\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m\n\u001b[1;32m   2564\u001b[0m )\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/cs135_env/lib/python3.10/site-packages/sklearn/utils/validation.py:443\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \n\u001b[1;32m    426\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    442\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[0;32m--> 443\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/cs135_env/lib/python3.10/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1681, 89992]"
     ]
    }
   ],
   "source": [
    "ratings = ratings_set_df['rating'].values\n",
    "\n",
    "labels = (ratings >= 4.5).astype(int)\n",
    "\n",
    "SEED = 12345\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_vectors, labels, test_size=0.25, random_state=SEED)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs135_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
